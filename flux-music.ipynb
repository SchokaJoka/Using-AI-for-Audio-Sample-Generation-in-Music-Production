{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4998aa3-22da-4b75-92b5-766a041a1551",
   "metadata": {},
   "source": [
    "# Flux Music: Generate Music from Text Prompts\n",
    "\n",
    "Flux Music, by zsxkib, is an AI model that generates music based on textual descriptions. This project provides a Python interface to interact with the Flux Music model on Replicate, allowing users to create custom instrumental tracks.\n",
    "\n",
    "## ‚ú® Features\n",
    "\n",
    "* **Text-to-Music Generation:** Generate original instrumental music by providing descriptive text prompts.\n",
    "* **Prompt Enhancement:** Optionally leverage `openai/gpt-4o` to expand concise user prompts into more detailed musical descriptions, leading to richer and more specific outputs.\n",
    "* **WAV Output:** Receive the generated music as a `.wav` audio file.\n",
    "* **Melspectrogram Output:** Additionally, get a melspectrogram of the generated audio for visual analysis.\n",
    "\n",
    "## ‚öôÔ∏è How It Works\n",
    "\n",
    "The core functionality involves sending a text prompt to the Flux Music model hosted on Replicate. The model then processes this prompt to generate an audio track.\n",
    "\n",
    "### 1. Prompt Preparation\n",
    "\n",
    "You can provide a direct prompt, or for more descriptive results, the example code demonstrates using `openai/gpt-4o` as a \"music producer assistant\". This assistant takes a short `user_prompt` (e.g., \"soul with funky guitar\") and expands it into a more detailed description suitable for the music generation model.\n",
    "\n",
    "### 2. Music Generation\n",
    "\n",
    "The expanded prompt is then passed to the `zsxkib/flux-music` model on Replicate. The model uses parameters like `steps`, `model_version`, `guidance_scale`, and `negative_prompt` to control the generation process.\n",
    "\n",
    "### 3. Output Retrieval\n",
    "\n",
    "The model returns both a WAV audio file and its corresponding melspectrogram.\n",
    "\n",
    "## üöÄ Getting Started\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "* Python 3.8+\n",
    "* A Replicate API Token\n",
    "\n",
    "### Installation\n",
    "\n",
    "1.  **Install the Replicate Python client:**\n",
    "    ```bash\n",
    "    pip install replicate\n",
    "    ```\n",
    "\n",
    "### Usage\n",
    "\n",
    "1.  **Set your Replicate API Token:**\n",
    "    Replace `\"YOUR_REPLICATE_API_TOKEN\"` with your actual token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c5e85e-ea64-47bd-92f7-7e191c4742be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"REPLICATE_API_TOKEN\"] = \"your_token_here\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5be215-2d14-4e3a-b000-d55f773218b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install replicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054044c9-902d-4b27-a552-b3cdfe998166",
   "metadata": {},
   "outputs": [],
   "source": [
    "import replicate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772c5bcd-c82d-4694-9e3b-759c52b1caa1",
   "metadata": {},
   "source": [
    "2.  **Generate music:**\n",
    "    The following example demonstrates how to use `openai/gpt-4o` to create a detailed prompt before generating the music."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942886ea-9a2d-4192-ae90-78429d99f3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = \"soul with funky guitar\"\n",
    "\n",
    "\n",
    "# === Text Prompt ===\n",
    "gpt_output_prompt = replicate.run(\n",
    "    \"openai/gpt-4o\",\n",
    "    input={\n",
    "        \"top_p\": 1,\n",
    "        \"prompt\": user_prompt,\n",
    "        \"temperature\": 1,\n",
    "        \"system_prompt\": \"(ONLY GIVE THE PROMPT) You are a music producer assistant. Specifically you are responsible for creating a description of the instrumental music i want to generate to feed another AI Model. the main focus is to fully document what type of music the user wants. Write maximum 3 Sentences. make it short\",\n",
    "        \"presence_penalty\": 0,\n",
    "        \"frequency_penalty\": 0,\n",
    "        \"max_completion_tokens\": 4096\n",
    "    }\n",
    ")\n",
    "gpt_output_prompt = \"\".join(gpt_output_prompt) if isinstance(gpt_output_prompt, list) else gpt_output_prompt\n",
    "print(gpt_output_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bf9118-c89b-4b52-a997-1f1399d31406",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = replicate.run(\n",
    "    \"zsxkib/flux-music:eebfed4a1749bb1172f005f71fac5a1e0377502ec149c9d02b56ac1de3aa9f07\",\n",
    "    input={\n",
    "        \"steps\": 50,\n",
    "        \"prompt\": gpt_output_prompt,\n",
    "        \"model_version\": \"base\",\n",
    "        \"guidance_scale\": 7,\n",
    "        \"negative_prompt\": \"\",\n",
    "        \"save_spectrogram\": True\n",
    "    }\n",
    ")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46cf8a38-627a-473b-b3a7-77c0801edbaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "wav_file = output['wav']\n",
    "\n",
    "# Get the URL of the WAV file\n",
    "wav_url = wav_file.url\n",
    "print(wav_url)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
